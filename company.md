---
title: Company
layout: company
meta_description: A scalable query engine for web scraping, data mashup, and acceptance QA. Certified for Apache Spark.
meta_keywords: Tribbloid, SpookyStuff, Apache Spark, web scraper, data mining
summary: SpookyStuff is a scalable query engine for web scraping, data mashup, and acceptance QA
---

## Challenge

### Autonomous Learning Cluster

Supported by a group of specialists in scalable computing, machine learning and open-source software. We seek to integrate autonomous data acquisition/valorisation into scalable machine learning pipeline end-to-end, proactively using the Internet, telemetrics and sensor network to train and improve itself.

We believe that state-of-the-art AI algorithms and architectures perform best on large amount of real data, unconstrained of down-sampling, manual annotation and cost control. As a result, our solutions leverage the best of web crawling, APIs, unstructured data management and ensemble/proactive learning algorithm, and scale all components adaptively to perform under varying resources and minimal supervision.

## Team

### Peng Cheng (Co-Founder, Lead Committer)

- Specialization: Apache Spark, Algorithms, Computer Vision
- Research Exp.: Human Detection, Kernel Machine Approximation, Stochastic Gradient Descent
- Eng. Exp.: Recommendation Engine, Parallel Data Encryption, SpookyStuff, ISpark
- Alma Mater: University of Wollongong, NSW, Australia. (Master of Computer Science)
- Language: Mandarin, English
- Blood Type: O Negative
- Interests: Cycling, Power Lifting, Drone Control

## Career

Consider yourself a rule breaker? Welcome to submit your resume to [yo@tribbloids.com](yo@tribbloids.com)

### Big Data Engineer

Must have:

- Understanding of algorithm, complexity, scalability, parallel computing and optimization
- Proficient in the art of persuasion â€“ you'll use that a lot to persuade others to adopt your idea!
- Prefer proof-of-concept, coordination and convergence of vision over brute force and unproven hypotheses
- object oriented programming
- Scala/Java
- git
- maven/sbt/gradle
- prefer Linux for daily use over Windows: RHEL/ubuntu preferred, MacOS also works if you know it well

Good to have:

- active open-source project committer
- Any machine learning/artificial intelligence R&D experience will be helpful
- Apache Spark
- Apache Hadoop and its ecosystem
- functional programming
- understanding of HTTP protocal, RESTful API and JSON format
- operational experience in Amazon EC2/S3
- prefer to work on personal laptop over dedicated workstation
- experience in JavaScript, any of its frameworks or Python a plus.
